\documentclass[11pt,letterpaper]{article}


\usepackage{bm}
\usepackage{geometry}
\usepackage{natbib,graphics,epsfig,rotate,lscape,graphicx,amsmath,amsthm,amssymb,float,amsfonts,amsbsy,hyperref,delarray,sectsty,amsfonts,amscd,pifont}
\usepackage{color,multirow}
\usepackage{algorithmic}
\usepackage{algorithm}



\geometry{letterpaper,left=1in,right=1in,top=1.2in,bottom=1.1in}
\bibliographystyle{plain}
\allowdisplaybreaks
%\def\references{\bibliography{C:/hanstex/macros/bib/11-1-11}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{Prop}{Proposition}
\newtheorem{aside}{Aside}
\newtheorem{claim}{Claim}
\newtheorem{conjecture}{Conjecture}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\newcommand{\bea}{\begin{eqnarray*}}
\newcommand{\eea}{\end{eqnarray*}}
\newcommand{\ed}{\end{document}}
\newcommand{\no}{\noindent}
\newcommand{\et}{\textit{et al. }}
\newcommand{\btab}{\begin{tabular}}
\newcommand{\etab}{\end{tabular}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\np}{\newpage}
\newcommand{\la}{\label}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\bfi}{\begin{figure}}
\newcommand{\efi}{\end{figure}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\bdes}{\begin{description}}
\newcommand{\edes}{\end{description}}
\newcommand{\bay}{\begin{array}}
\newcommand{\eay}{\end{array}}
\newcommand{\bs}{\boldsymbol}
\newcommand{\mb}{\boldsymbol}
\newcommand{\nn}{\nonumber}
\newcommand{\sm}{\vspace{.2cm}}
\newcommand{\bla}{\textcolor{black}}
\newcommand{\blu}{\textcolor{blue}}
\newcommand{\red}{\textcolor{red}}

\def\stackunder#1#2{\mathrel{\mathop{#2}\limits_{#1}}}
\renewcommand{\labelenumi}{(\roman{enumi})}
\newcommand{\Comment}[1]{\textcolor{blue}{\textsc{#1}}}


\def\Ver{1}
\def\LongVer{1}
%%------------------------------ begin long version
%\if\Ver\LongVer{ 
%{\flushleft\textcolor{blue}{$\downarrow$---------begin long version---------}}\newline
%
%{\flushleft\textcolor{blue}{$\uparrow$------------end long version---------}}\newline
%} \fi
%%------------------------------ end long version




\newcommand{\be}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\renewcommand{\baselinestretch}{1}%{1.7}

%====================================================================================
\begin{document}
\begin{center}
\Large \bf
Lemmas for the Law of the Iterated Logorithm (for coin flips).
\end{center}

\paragraph{Definitions}
\begin{enumerate}
\item $(\Omega, \mathcal F, P) = ((0,1], \mathcal B^{(0,1]}, \text{spinner model})$.
\item For $w\in\Omega$ let 
\[d_k(w)= \text{``$k^\text{th}$ binary digit of $w$''}.\] 
Notice that $(d_1,d_2,d_3,\ldots)$ models an infinite fair coin flip model.
\item For $w\in\Omega$ let 
\[r_k(w):= 2d_k(w)- 1. \] 
Notice that $r_k(w)$ is plus or minus zero. Also notice that the expected value of $r_k(w)$ is 0 (i.e. $\int_0^1 r_k(w)dw =0$) and the variance of $r_k(w)$ is 1 (i.e. $\int_0^1 r^2_k(w)dw-0^2 =1$).
\item  For $w\in\Omega$ let
\begin{align*}
s_n(w)&:=\sum_{k=1}^n {r_k(w)}\\
&= 2\left(\sum_{k=1}^n {d_k(w)}\right) -n\\
&= \text{excess of heads in $n$ tosses}
\end{align*}
%\item  For $w\in\Omega$ let 
%\[m_n(w):= \max_{1\leq j\leq n} s_j(w).\]
\end{enumerate}


%%%%%%%%%%%%%%%%%%%
\paragraph{Lemma 1.}
For all $n\in \Bbb N$ and $x>0$, then \\$ P\bigl(s_n/\sqrt{n} \geq x\bigr)\leq \exp\bigl[ -\frac{x^2}{2} \bigr]$.

%%%%%%%%%%%%%%%%%%%
\paragraph{Lemma 2.}
For all $n\in \Bbb N$ and any sequence $0\leq x_n \rightarrow \infty$ such that $x_n/\sqrt{n}\rightarrow 0$ as $n\rightarrow \infty$ then \\
$ P\bigl(s_n/\sqrt{n} \geq x_n\bigr)\geq \exp\bigl[ -\frac{x_n^2}{2} (1+o(1))\bigr]$.


%%%%%%%%%%%%%%%%%%%
\paragraph{Lemma 3.}
For all $n\in\Bbb N$ and every nonnegative integer $c$\\
$ P\bigl( \max_{1\leq j\leq n} s_j \geq c \bigr)\leq 2P(s_n\geq c)$.


%%%%%%%%%%%%
\paragraph{Comments.} 
The idea is that Lemmas 1 and 2 give you good approximations to   $P\bigl(s_n/\sqrt{n} \geq x\bigr)$ for large-ish values of $x$: large compared to $0$ but still small compared to $\sqrt{n}$ (if $x$ was larger than $\sqrt{n}$ then Lemma 2 could not be true since $P(s_n> n)=0$). This is the key for deriving the Law of the Iterated Logorithm. Notice that you proved Lemma 1 in homework 1 from first principles. %However, as you will see in the proof below, it is easy to prove if you assume Markov's inequality and use the fact that \mbox{$\frac{e^x + e^{-x}}{2} \leq \exp\left({x^2/2}\right)$} (which is also easy to see taking Taylor expansions to the left hand side).  
Lemma 2 is a basic variant on a large deviation result for  the rare events  $\{  s_n/\sqrt{n} \geq x_n\}$. 


\newpage
%%%%%%%%%%%%%%%%%%
\paragraph{Proof of Lemma 1.}
This was proved in homework 1, exercise 2.
\begin{align*}
 P\bigl(s_n/\sqrt{n} \geq x\bigr) &\overset{\textcolor{blue}{key}}=  P\bigl(x s_n/\sqrt{n} \geq x^2\bigr),\quad\text{since $x>0$} \\
 &\overset{\textcolor{blue}{key}}= P\bigl(e^{x s_n/\sqrt{n} } \geq e^{x^2}\bigr),\quad\text{since $e^x$ monotonically increases in $x$} \\
 &\overset{\textcolor{blue}{key}}\leq \frac{Ee^{x s_n/\sqrt{n}}}{e^{x^2}},\quad\text{by Markov since $e^{x s_n/\sqrt{n}}\geq 0$}\\
 &=e^{-x^2}E\exp\left[\frac{x}{\sqrt{n}} \sum_{k=1}^n {r_k} \right]\\
  &=e^{-x^2}E\prod_{k=1}^n\exp\left[\frac{x}{\sqrt{n}}  {r_k} \right]\\
    &=e^{-x^2}\prod_{k=1}^nE\exp\left[\frac{x}{\sqrt{n}}  {r_k} \right],\quad\text{by independence}\\
 &=e^{-x^2}\left(E\exp\left[\frac{x}{\sqrt{n}}  {r_1} \right]\right)^n,\quad\text{since the $r_k$'s are identically distributed}\\
 &=e^{-x^2}\left( \frac{1}{2}e^\frac{x}{\sqrt{n}} + \frac{1}{2}e^\frac{-x}{\sqrt{n}}\right)^n,\quad\text{since $r_k=\pm 1$ with equal prob}\\
 &\overset{\textcolor{blue}{key}}\leq e^{-x^2}\left(e^\frac{x^2}{2n}  \right)^n,\quad\text{since $\frac{e^x + e^{-x}}{2} \leq e^{x^2/2}$}\\
  &\leq e^{-x^2}e^{{x^2}/{2}} \\
   &\leq e^{-{x^2}/{2}}.
\end{align*}
QED.

%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Proof of Lemma 2.}
Let $\xi_n$ be a positive integer having the same parity as $n$ (so $\xi_n$ is even if $n$ even and  $\xi_n$ is odd if $n$ odd) and suppose $\xi_n/n\rightarrow 0$.
Since $\sum_{k=1}^n d_k\sim \text{Bin}(n,1/2)$ we have that
\begin{align}
P(s_n = \xi_n)
&=P\Bigl(\sum_{k=1}^n d_k = (\xi_n +n)/2\Bigr)\nonumber\\
&=\begin{pmatrix} n \\ (\xi_n +n)/2 \end{pmatrix} \frac{1}{2^n}\nonumber\\
&=\frac{n!}{\frac{\xi_n +n}{2}! \frac{n -\xi_n}{2}! } \frac{1}{2^n}\nonumber\\
& = \frac{2}{\sqrt{2\pi n}} [1+o(1)] \exp\left( - \frac{(1+o(1)) \xi_n^2}{2n} \right)\label{isright}
\end{align}
Notice that without the parity assumption $(\xi_n +n)/2$ would be a fraction and one would have that $P\Bigl(\sum_{k=1}^n d_k = (\xi_n +n)/2\Bigr)=0$.


To see why (\ref{isright}) is true notice that by Stirling's formula we have $n! = (1+o(1)) \sqrt{2\pi n} n^n e^{-n}$. Therefore
\begin{align*}
\frac{n!}{\frac{\xi_n +n}{2}! \frac{n -\xi_n}{2}! }  \frac{1}{2^n}
&= \frac{(1+o(1))}{(1+o(1))^2}\times \frac{\sqrt{2\pi n} }{\sqrt{2\pi (n+\xi_n)/2}\sqrt{2\pi (n-\xi_n)/2}  } \\
&\qquad\qquad\times\frac{n^n}{ (n+\xi_n)^{(n+\xi_n)/2}(n-\xi_n)^{(n-\xi_n)/2}} \times \frac{ e^{-n}}{ e^{-(n+\xi_n)/2} e^{-(n-\xi_n)/2}  } \\
&= \frac{(1+o(1))}{(1+o(1))^2}\times \underbrace{\frac{1 }{\sqrt{2\pi (n+\xi_n) (n-\xi_n)/(4n)}  }}_{=:I}\times\underbrace{\left(\frac{n}{n+\xi_n}\right)^{(n+\xi_n)/2}\left(\frac{n}{n-\xi_n}\right)^{(n-\xi_n)/2}}_{=:I\!I}
\end{align*}
Notice
\begin{align*}
I&=\frac{1 }{\sqrt{2\pi (n+\xi_n) (n-\xi_n)/(4n)}  }\\
 &= \frac{2}{\sqrt{2\pi n}}\times \frac{1}{\sqrt{ (n+\xi_n) (n-\xi_n)/(n^2)}}\\
&= \frac{2}{\sqrt{2\pi n}}\times \frac{1}{\sqrt{1   -(\xi_n/n)^2}}= \frac{2}{\sqrt{2\pi n}} (1+o(1)).
\end{align*}
Secondly notice that $(1+x)\log(1+x)= x +\frac{1}{2}x^2+O(x^3)$ as $x\rightarrow 0$. Therefore
\begin{align*}
\log I\!I&= -\frac{1}{2}\bigl[ (n+\xi_n)\log \bigl(1+\frac{\xi_n}{n}\bigr) +  (n-\xi_n)\log \bigl(1-\frac{\xi_n}{n}\bigr) \bigr] \\
&=-\frac{n}{2}\bigl[\frac{\xi_n}{n} +\frac{1}{2}\frac{\xi_n^2}{n^2} - \frac{\xi_n}{n} +\frac{1}{2}\frac{\xi_n^2}{n^2}+O({\xi^3_n}/{n}^3)  \bigr] \\
&=-\frac{n}{2}\bigl[  \frac{\xi_n^2}{n^2}  +O({\xi^3_n}/{n}^3)  \bigr] = -\frac{\xi_n^2}{2n}\bigl[ 1  +\underbrace{O({\xi_n}/{n}}_{o(1)})  \bigr].
\end{align*}
To finish notice that   $\frac{(1+o(1))^2}{(1+o(1))^2} = [1+o(1)]$ which implies (\ref{isright}).
%\begin{align*}
%P(w\in\Omega:s_n(w) = \xi_n)& = \frac{2}{\sqrt{2\pi n}} \exp\left( - \frac{(1+o(1)) \xi_n^2}{2n} \right)\\
%& = \frac{2}{\sqrt{2\pi n}} \exp\Bigl(-\frac{\xi_n^2}{2n} \underbrace{\left[-\frac{2n}{\xi_n^2}o(1)\right]}_{\shortstack{$= o(1)$, \text{since} \\\text{$\sqrt{n}/\xi_n = o(1)$ }}} - \frac{(1+o(1)) \xi_n^2}{2n} \Bigr)\\
%& = \frac{2}{\sqrt{2\pi n}} \exp\left( - \frac{(1+o(1)) \xi_n^2}{2n} \right)
%\end{align*}
%\textcolor{blue}{I still don't see why we need $\sqrt{n}/\xi_n = o(1)$ for this preliminary step. The results seem to go fine with the approximation $P(w\in\Omega:s_n(w) = \xi_n) = \frac{2}{\sqrt{2\pi n}}(1+o(1)) \exp\left( - \frac{(1+o(1)) \xi_n^2}{2n} \right)
%$ }

Now to finish the proof first let $\mathcal I_n$ denote the set of indices between $\sqrt{n}x_n$ and $\sqrt{n}x_n + 2\sqrt{\pi n}$ which have the same parity at $n$. Notice that the number of indicies in $\mathcal I_n$ is $\sqrt{\pi  n}+ O(1)$.  Also let $i_n$ be the maximum indicie in $\mathcal I_n$ so that $i_n = \sqrt{n}x_n + 2\sqrt{\pi n} + O(1)$. Now
\begin{align*}
P(s_n\geq \sqrt{n} x_n)&\geq \sum_{i\in\mathcal I_n} P(s_n = i)\\
&\geq \sum_{i\in\mathcal I_n} P(s_n = i_n),\quad \text{since $\begin{pmatrix} n \\ (i +n)/2 \end{pmatrix}\geq \begin{pmatrix} n \\ (i_n +n)/2 \end{pmatrix}$}\\
&= [\sqrt{\pi n}+ O(1)]P(s_n = i_n)\\
&=\underbrace{ [\sqrt{\pi n}+ O(1)][1+o(1)]\frac{2}{\sqrt{2\pi n}} }_{ = \sqrt 2 +o(1)} \exp\left( - \frac{(1+o(1)) i_n^2}{2n} \right),\quad \text{by (\ref{isright}) since $i_n/n= O(x_n/\sqrt{n}) \rightarrow 0$} \\
%&= [\sqrt{\pi n}+ O(1)]\frac{2}{\sqrt{2\pi n}} \exp\left( - \frac{(1+o(1)) i_n^2}{2n} \right) \\
&= \sqrt{2} \exp\left( - \frac{(1+o(1)) i_n^2}{2n} \right) + \underbrace{ o(1)\exp\left( - \frac{(1+o(1)) i_n^2}{2n} \right)}_\text{$=o(1)$ since $i_n/\sqrt{n}=O(x_n)\rightarrow \infty$  }\\
&\geq \exp\left( - \frac{(1+o(1)) i_n^2}{2n} \right).
\end{align*}
To finish the proof simply notice that 
\begin{align*}
- \frac{(1+o(1)) i_n^2}{2n} & = - \frac{(1+o(1)) \bigl[\sqrt{n}x_n +2\sqrt{\pi n} + O(1) \bigr]^2}{2n} \\
& = - \frac{x_n^2}{2} (1+o(1)) \bigl[1 + 2\sqrt{\pi}/x_n + O(1/(x_n\sqrt{n}) \bigr]^2 \\
& = - \frac{x_n^2}{2} (1+o(1)) ,\quad\text{since $x_n\rightarrow \infty$}.
\end{align*}
Therefore $P(s_n\geq \sqrt{n} x_n) \geq \exp\bigl[ - \frac{x_n^2}{2} (1+o(1))  \Bigr]$.
QED.

\newpage
%%%%%%%%%%
\paragraph{Proof of Lemma 3.}
First write
\begin{align*}
P\bigl( \max_{1\leq j\leq n} s_j \geq c \bigr)&= P\bigl( \max_{1\leq j\leq n} s_j \geq c,\, s_n \geq c \bigr) + P\bigl( \max_{1\leq j\leq n} s_j \geq c,\, s_n < c  \bigr)\\
&= P\bigl( s_n \geq c \bigr) + P\bigl( \max_{1\leq j\leq n} s_j \geq c,\, s_n < c  \bigr)
\end{align*}
where the last equality follows since $\{ s_n \geq c\}\subset \{  \max_{1\leq j\leq n} s_j \geq c\}$.
Therefore all that remains is to show $ P\bigl( \max_{1\leq j\leq n} s_j \geq c,\, s_n < c  \bigr)\leq  P\bigl( s_n \geq c \bigr)$.
Start by segmenting the event $\{\max_{1\leq j\leq n} s_j \geq c\}$ corresponding to the first indicie $j$ for which $s_j= c$ (this must occur when  $ \max_{1\leq j\leq n} s_j \geq c$ since $s_n$ goes up or down with jumps of size $1$ and $c$ is a nonnegative integer). In particular, write
\[ \{  \max_{1\leq j\leq n} s_j \geq c \} =\bigcup_{j=1}^n \underbrace{\{s_1<c, \, \ldots,\, s_{j-1}<c,\, s_j= c \}}_{=:F_j} \]
Now 
\begin{align}
\{ \max_{1\leq j\leq n} s_j \geq c\}\cap\{s_n < c\} &= \bigcup_{j=1}^n F_j\cap  \{s_n < c\}\\
&= \bigcup_{j=1}^n \underbrace{F_j\cap  \{s_n - s_j<0\}}_\text{these are disjoint since the $F_j$'s are}\quad\text{since $w\in F_j$ implies $s_j=c$}.
\end{align}
Now notice two things. First $P(s_n - s_j<0)=P(s_n - s_j>0) $ by symmetry. Secondly, since $\{s_n - s_j<0 \}\in \sigma\langle r_{j+1},\ldots, r_n\rangle$ and $F_j\in \sigma\langle r_1,\ldots, r_j\rangle$, the event $\{s_n - s_j<0 \}$ is independent of $F_j$ (by ANOVA).
Therefore
\begin{align*}
P\bigl( \max_{1\leq j\leq n} s_j \geq c,\, s_n < c \bigr)&= \sum_{j=1}^n P\bigl( F_j\cap  \{s_n - s_j<0\} \bigr)\\
& = \sum_{j=1}^n P\bigl( F_j\bigr)P\bigl( s_n - s_j<0 \bigr)\text{ by independence}\\
& = \sum_{j=1}^n P\bigl( F_j\bigr)P\bigl( s_n - s_j>0 \bigr)\text{ by symmetry}\\
& = \sum_{j=1}^n P\bigl( F_j \cap \{s_n - s_j>0\} \bigr)\text{ by independence again}\\
& = \sum_{j=1}^n P\bigl( F_j \cap \{s_n > c\} \bigr)\text{ since $w\in F_j$ implies $s_j=c$}\\
&= P\bigl( \max_{1\leq j\leq n} s_j \geq c,\, s_n > c \bigr)\\
&\leq  P\bigl( s_n > c \bigr) \\
&\leq  P\bigl( s_n \geq c \bigr).
\end{align*}
Therefore $P\bigl( \max_{1\leq j\leq n} s_j \geq c \bigr)\leq 2 P\bigl( s_n \geq c \bigr)$.
QED.

\end{document}


















